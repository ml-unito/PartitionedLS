<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Documentation · PartitionedLS.jl</title><meta name="title" content="Documentation · PartitionedLS.jl"/><meta property="og:title" content="Documentation · PartitionedLS.jl"/><meta property="twitter:title" content="Documentation · PartitionedLS.jl"/><meta name="description" content="Documentation for PartitionedLS.jl."/><meta property="og:description" content="Documentation for PartitionedLS.jl."/><meta property="twitter:description" content="Documentation for PartitionedLS.jl."/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href><img src="assets/logo.png" alt="PartitionedLS.jl logo"/></a><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Documentation</a><ul class="internal"><li><a class="tocitem" href="#The-model"><span>The model</span></a></li><li><a class="tocitem" href="#To-install-this-library"><span>To install this library</span></a></li><li><a class="tocitem" href="#To-use-this-library"><span>To use this library</span></a></li><li><a class="tocitem" href="#API-Documentation"><span>API Documentation</span></a></li></ul></li><li><a class="tocitem" href="examples/example/">Example</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Documentation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Documentation</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/ml-unito/PartitionedLS.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/ml-unito/PartitionedLS.jl/blob/master/docs/src/index.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Partitioned-Least-Squares"><a class="docs-heading-anchor" href="#Partitioned-Least-Squares">Partitioned Least Squares</a><a id="Partitioned-Least-Squares-1"></a><a class="docs-heading-anchor-permalink" href="#Partitioned-Least-Squares" title="Permalink"></a></h1><p>Linear least squares is one of the most widely used regression methods among scientists in many fields. The simplicity of the model allows this method to be used when data is scarce and it is usually appealing to practitioners that need to gather some insight into the problem by inspecting the values of the learnt parameters. PartitionedLS is a variant of the linear least squares model allowing practitioners to partition the input features into groups of variables that they require to contribute similarly to the final result.</p><p>An example of analysing a dataset using PartitionedLS is given <a href="examples/example/">here</a></p><h2 id="The-model"><a class="docs-heading-anchor" href="#The-model">The model</a><a id="The-model-1"></a><a class="docs-heading-anchor-permalink" href="#The-model" title="Permalink"></a></h2><p>The Partitioned Least Squares model is formally defined as:</p><p class="math-container">\[\begin{gather*}
\text{minimize}_{\mathbf{\alpha}, \mathbf{\beta}} \| \mathbf{X} \times (\mathbf{P} \circ \mathbf{\alpha}) \times \mathbf{\beta} - \mathbf{y} \|_2^2 \\
\begin{aligned}
\quad s.t.\quad  &amp;\mathbf{\alpha}  \succeq 0\\
                    &amp;\mathbf{P}^T \times \mathbf{\alpha} = \mathbf{1}.
\end{aligned}
\end{gather*}\]</p><p>where: </p><ul><li><span>$\mathbf{X}$</span> is a <span>$N × M$</span> matrix or table with <code>Continuous</code> element scitype containing the         examples for which the predictions are sought. Check column scitypes         of a table <code>X</code> with <code>schema(X)</code>.</li><li><span>$\mathbf{y}$</span> is a <span>$N$</span> vector with <code>Continuous</code> element scitype. Check scitype with <code>scitype(y)</code>. </li><li><span>$\mathbf{P}$</span> is a <span>$M × K$</span> <code>Int</code> matrix specifying how to partition the <span>$M$</span> attributes into <span>$K$</span> subsets. <span>$P_{m,k}$</span> should be 1 if attribute number <span>$m$</span> belongs to partition <span>$k$</span>.</li><li><span>$\mathbf{\beta}$</span> is a vector weighting the importance of each set of attributes in the partition;</li><li><span>$\mathbf{\alpha}$</span> is a vector weighting the importance of each attribute within one of the sets in the partition. Note that the constraints imply that for each set in the partition the weights of the corresponding <span>$\alpha$</span> variables are all positive and sum to <span>$1$</span>.</li></ul><p>The PartitionedLS problem is non-convex and NP-complete. The library provides two algorithms to solve the problem anyway: an iterative algorithm based on the Alternating Least Squares approach and an optimal algorithm that guarantees requiring however exponential time in the cardinality of the partition (i.e., it is mainly useful when <span>$K$</span> is small).</p><p>More details can be found in the paper <a href="https://arxiv.org/abs/2006.16202">Partitioned Least Squares</a>.</p><h2 id="To-install-this-library"><a class="docs-heading-anchor" href="#To-install-this-library">To install this library</a><a id="To-install-this-library-1"></a><a class="docs-heading-anchor-permalink" href="#To-install-this-library" title="Permalink"></a></h2><p>Just add it as a dependency to your Julia environment. Launch julia from the main directory of your project and enter the following commands:</p><pre><code class="language-julia hljs"># Opens the package manager REPL
]

# Activate you local environment (can be skipped if you want to install the library globally)
activate .

# Adds the library to the environment
add PartitionedLS</code></pre><h2 id="To-use-this-library"><a class="docs-heading-anchor" href="#To-use-this-library">To use this library</a><a id="To-use-this-library-1"></a><a class="docs-heading-anchor-permalink" href="#To-use-this-library" title="Permalink"></a></h2><p>You will need a matrix P describing the partitioning of your variables, e.g.:</p><pre><code class="language-julia hljs">P = [[1 0]; 
     [1 0]; 
     [0 1]]</code></pre><p>specifies that the first and the second variable belongs to the first partition, while the third variable belongs to the second.</p><p>You have then the choice to use either the standard interface or the MLJ interface. </p><h3 id="Standard-interface"><a class="docs-heading-anchor" href="#Standard-interface">Standard interface</a><a id="Standard-interface-1"></a><a class="docs-heading-anchor-permalink" href="#Standard-interface" title="Permalink"></a></h3><p>The standard interface defines a <code>fit</code> function for each of the implemented algorithms. The function returns a tuple containing:</p><ul><li>a <code>PartLSFitResult</code> object containing the model and the parameters found by the algorithm;</li><li><code>nothing</code> (this is mandated by the MLJ interface, but it is not used in this case).</li><li>a NamedTuple containing some additional information.</li></ul><p>A complete example:</p><pre><code class="language-julia hljs">
using PartitionedLS

X = [[1. 2. 3.]; 
     [3. 3. 4.]; 
     [8. 1. 3.]; 
     [5. 3. 1.]]

y = [1.; 
     1.; 
     2.; 
     3.]

P = [[1 0]; 
     [1 0]; 
     [0 1]]


# fit using the optimal algorithm 
result = fit(Opt, X, y, P, η = 0.0)


# Make predictions on the given data matrix. The function works
# with results returned by anyone of the solvers.
predict(result[1], X)</code></pre><h3 id="MLJ-interface"><a class="docs-heading-anchor" href="#MLJ-interface">MLJ interface</a><a id="MLJ-interface-1"></a><a class="docs-heading-anchor-permalink" href="#MLJ-interface" title="Permalink"></a></h3><p>The MLJ interface is a allows you to use the library in a more MLJ-like fashion. The interface is defined by the <a href="#PartitionedLS.PartLS"><code>PartLS</code></a> model, which can be used in the MLJ framework. The model can be used in the same way as any other MLJ model.</p><p>A complete example:</p><pre><code class="language-julia hljs">using MLJ
using PartitionedLS

X = [[1. 2. 3.]; 
     [3. 3. 4.]; 
     [8. 1. 3.]; 
     [5. 3. 1.]]

y = [1.;
     1.;
     2.;
     3.]

P = [[1 0]; 
     [1 0]; 
     [0 1]]

# Define the model

model = PartLS(P=P, Optimizer=Opt, η=0.0)

# Fit the model
mach = machine(model, X, y)
fit!(mach)

# Make predictions
predict(mach, X)</code></pre><h2 id="API-Documentation"><a class="docs-heading-anchor" href="#API-Documentation">API Documentation</a><a id="API-Documentation-1"></a><a class="docs-heading-anchor-permalink" href="#API-Documentation" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PartitionedLS.PartLS" href="#PartitionedLS.PartLS"><code>PartitionedLS.PartLS</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">PartLS</code></pre><p>A model type for fitting a partitioned least squares model to data. Both an MLJ and native interfacew are provided.</p><p><strong>MLJ Interface</strong></p><p>From MLJ, the type can be imported using</p><p>PartLS = @load PartLS pkg=PartitionedLS</p><p>Construct an instance with default hyper-parameters using the syntax <code>model = PartLS()</code>. Provide keyword arguments to override hyper-parameter defaults, as in <code>model = PartLS(P=...)</code>.</p><p><strong>Training data</strong></p><p>In MLJ or MLJBase, bind an instance <code>model</code> to data with</p><pre><code class="nohighlight hljs">mach = machine(model, X, y)</code></pre><p>where</p><ul><li><code>X</code>: any matrix or table with <code>Continuous</code> element scitype.       Check column scitypes of a table <code>X</code> with <code>schema(X)</code>.</li></ul><p>Train the machine using <code>fit!(mach)</code>.</p><p><strong>Hyper-parameters</strong></p><ul><li><p><code>Optimizer</code>: the optimization algorithm to use. It can be <code>Opt</code>, <code>Alt</code> or <code>BnB</code> (names exported by <code>PartitionedLS.jl</code>).</p></li><li><p><code>P</code>: the partition matrix. It is a binary matrix where each row corresponds to a partition and each column corresponds to a feature. The element <code>P_{k, i} = 1</code> if feature <code>i</code> belongs to partition <code>k</code>.</p></li><li><p><code>η</code>: the regularization parameter. It controls the strength of the regularization.</p></li><li><p><code>ϵ</code>: the tolerance parameter. It is used to determine when the Alt optimization algorithm has converged. Only used by the <code>Alt</code> algorithm.</p></li><li><p><code>T</code>: the maximum number of iterations. It is used to determine when to stop the Alt optimization algorithm has converged. Only used by the <code>Alt</code> algorithm.</p></li><li><p><code>rng</code>: the random number generator to use.</p><ul><li><p>If <code>nothing</code>, the global random number generator <code>rand</code> is used.</p></li><li><p>If an integer, the global number generator <code>rand</code> is used after seeding it with the given integer.</p></li><li><p>If an object of type <code>AbstractRNG</code>, the given random number generator is used.</p></li></ul></li></ul><p><strong>Operations</strong></p><ul><li><code>predict(mach, Xnew)</code>: return the predictions of the model on new data <code>Xnew</code></li></ul><p><strong>Fitted parameters</strong></p><p>The fields of <code>fitted_params(mach)</code> are:</p><ul><li><code>α</code>: the values of the α variables. For each partition <code>k</code>, it holds the values of the α variables are such that <span>$\sum_{i \in P_k} \alpha_{k} = 1$</span>.</li><li><code>β</code>: the values of the β variables. For each partition <code>k</code>, <code>β_k</code> is the coefficient that multiplies the features in the k-th partition.</li><li><code>t</code>: the intercept term of the model.</li><li><code>P</code>: the partition matrix. It is a binary matrix where each row corresponds to a partition and each column corresponds to a feature. The element <code>P_{k, i} = 1</code> if feature <code>i</code> belongs to partition <code>k</code>.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">PartLS = @load PartLS pkg=PartitionedLS

X = [[1. 2. 3.];
     [3. 3. 4.];
     [8. 1. 3.];
     [5. 3. 1.]]

y = [1.;
     1.;
     2.;
     3.]

P = [[1 0];
     [1 0];
     [0 1]]


model = PartLS(P=P)
mach = machine(model, X, y) |&gt; fit!

# predictions on the training set:
predict(mach, X)
</code></pre><p><strong>Native Interface</strong></p><pre><code class="nohighlight hljs">using PartitionedLS

X = [[1. 2. 3.];
     [3. 3. 4.];
     [8. 1. 3.];
     [5. 3. 1.]]

y = [1.;
     1.;
     2.;
     3.]

P = [[1 0];
     [1 0];
     [0 1]]


# fit using the optimal algorithm
result = fit(Opt, X, y, P, η = 0.0)
y_hat = predict(result.model, X)</code></pre><p>For other <code>fit</code> keyword options, refer to the &quot;Hyper-parameters&quot; section for the MLJ interface.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ml-unito/PartitionedLS.jl/blob/b1ebd22e5675fc6fdc450ce2b7019b0cdf6d1ea5/src/PartitionedLS.jl#L161-L289">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PartitionedLS.PartLSFitResult" href="#PartitionedLS.PartLSFitResult"><code>PartitionedLS.PartLSFitResult</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">struct PartLSFitResult</code></pre><p>The PartLSFitResult struct represents the solution of the partitioned least squares problem.   It contains the values of the α and β variables, the intercept t and the partition matrix P.</p><p><strong>Fields</strong></p><ul><li><code>α::Vector{AbstractFloat}</code>: The values of the α variables. For each partition <span>$k$</span>, it holds the values of the α variables are such that <span>$\sum_{i \in P_k} \alpha_{k} = 1$</span>.</li></ul><ul><li><code>β::Vector{AbstractFloat}</code>: The values of the β variables. For each partition <span>$k$</span>, <span>$\beta_k$</span> is the coefficient that multiplies the features in the k-th partition.</li></ul><ul><li><code>t::AbstractFloat</code>: The intercept term of the model.</li></ul><ul><li><code>P::Matrix{Int64}</code>: The partition matrix. It is a binary matrix where each row corresponds to a partition and each column corresponds to a feature. The element <span>$P_{k, i} = 1$</span> if feature <span>$i$</span> belongs to partition <span>$k$</span>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ml-unito/PartitionedLS.jl/blob/b1ebd22e5675fc6fdc450ce2b7019b0cdf6d1ea5/src/PartitionedLS.jl#L19-L27">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJModelInterface.fit" href="#MLJModelInterface.fit"><code>MLJModelInterface.fit</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">fit(
    ::Type{Alt},
    X::Array{F&lt;:AbstractFloat, 2},
    y::Array{F&lt;:AbstractFloat, 1},
    P::Matrix{Int64};
    η,
    ϵ,
    T,
    nnlsalg,
    rng
) -&gt; Tuple{PartLSFitResult, Nothing, NamedTuple{(:opt,), &lt;:Tuple{Any}}}
</code></pre><p>Fits a PartitionedLS model by alternating the optimization of the α and β variables. This version uses  an optimization strategy based on non-negative-least-squaes solvers. This formulation is faster and  more numerically stable with respect to <code>fit(Alt, ...)</code>`.</p><p><strong>Arguments</strong></p><ul><li><code>X</code>: <span>$N × M$</span> matrix or table with <code>Continuous</code> element scitype containing the         examples for which the predictions are sought. Check column scitypes         of a table <code>X</code> with <code>schema(X)</code>.</li><li><code>y</code>: <span>$N$</span> vector with <code>Continuous</code> element scitype. Check scitype with <code>scitype(y)</code>. </li><li><code>P</code>: <span>$M × K$</span> <code>Int</code> matrix specifying how to partition the <span>$M$</span> attributes into <span>$K$</span> subsets. <span>$P_{m,k}$</span> should be 1 if attribute number <span>$m$</span> belongs to partition <span>$k$</span>.</li><li><code>η</code>: regularization factor, higher values implies more regularized solutions. Default is 0.0.</li><li><code>T</code>: number of alternating loops to be performed. Default is 100.</li><li><code>ϵ</code>: minimum relative improvement in the objective function before stopping the optimization. Default is 1e-6</li><li><code>nnlsalg</code>: specific flavour of nnls algorithm to be used, possible values are <code>:pivot</code>, <code>:nnls</code>, <code>:fnnls</code>. Default is :nnls</li></ul><p><strong>Result</strong></p><p>A Tuple with the following fields:</p><ol><li>a <code>PartLSFitResult</code> object containing the fitted model</li><li>a <code>nothing</code> object</li><li>a NamedTuple with a field <code>opt</code> containing the optimal value of the objective function</li></ol></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ml-unito/PartitionedLS.jl/blob/b1ebd22e5675fc6fdc450ce2b7019b0cdf6d1ea5/src/PartitionedLSAlt.jl#L23-L49">source</a></section><section><div><pre><code class="language-julia hljs">#(TYPEDSIGNATURES)</code></pre><p>Fits a PartialLS Regression model to the given data and resturns the learnt model (see the Result section).  It uses a coplete enumeration strategy which is exponential in K, but guarantees to find the optimal solution.</p><p><strong>Arguments</strong></p><ul><li><code>X</code>: <span>$N × M$</span> matrix or table with <code>Continuous</code> element scitype containing the         examples for which the predictions are sought. Check column scitypes         of a table <code>X</code> with <code>schema(X)</code>.</li><li><code>y</code>: <span>$N$</span> vector with <code>Continuous</code> element scitype. Check scitype with <code>scitype(y)</code>. </li><li><code>P</code>: <span>$M × K$</span> <code>Int</code> matrix specifying how to partition the <span>$M$</span> attributes into <span>$K$</span> subsets. <span>$P_{m,k}$</span> should be 1 if attribute number <span>$m$</span> belongs to partition <span>$k$</span>.</li><li><code>η</code>: regularization factor, higher values implies more regularized solutions (default: 0.0)</li><li><code>returnAllSolutions</code>: if true an additional output is appended to the resulting tuple containing all solutions found during the algorithm.</li><li><code>nnlsalg</code>: the kind of nnls algorithm to be used during solving. Possible values are :pivot, :nnls, :fnnls (default: :nnls)</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">X = rand(100, 10)
y = rand(100)
P = [1 0 0; 0 1 0; 0 0 1; 1 1 0; 0 1 1]
result = fit(Opt, X, y, P)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ml-unito/PartitionedLS.jl/blob/b1ebd22e5675fc6fdc450ce2b7019b0cdf6d1ea5/src/PartitionedLSOpt.jl#L46-L72">source</a></section><section><div><pre><code class="language-julia hljs">fit(
    ::Type{BnB},
    X::Matrix{&lt;:AbstractFloat},
    y::AbstractVector{&lt;:AbstractFloat},
    P::Matrix{Int64};
    η,
    nnlsalg
) -&gt; Tuple{PartLSFitResult, Nothing, NamedTuple{(:opt, :nopen), &lt;:Tuple{Any, Any}}}
</code></pre><p>Implements the Branch and Bound algorithm to fit a Partitioned Least Squres model.</p><p><strong>Arguments</strong></p><ul><li><code>X</code>: <span>$N × M$</span> matrix or table with <code>Continuous</code> element scitype containing the         examples for which the predictions are sought. Check column scitypes         of a table <code>X</code> with <code>schema(X)</code>.</li><li><code>y</code>: <span>$N$</span> vector with <code>Continuous</code> element scitype. Check scitype with <code>scitype(y)</code>. </li><li><code>P</code>: <span>$M × K$</span> <code>Int</code> matrix specifying how to partition the <span>$M$</span> attributes into <span>$K$</span> subsets. <span>$P_{m,k}$</span> should be 1 if attribute number <span>$m$</span> belongs to partition <span>$k$</span>.</li><li><code>η</code>: regularization factor, higher values implies more regularized solutions (default: 0.0)</li><li>nnlsalg: the kind of nnls algorithm to be used during solving. Possible values are :pivot, :nnls, :fnnls (default: :nnls)</li></ul><p><strong>Result</strong></p><p>A tuple with the following fields:</p><ol><li>a <code>PartLSFitResult</code> object containing the fitted model</li><li>a <code>nothing</code> object</li><li>a NamedTuple with fields: <ul><li><code>opt</code> containing the optimal value of the objective function</li><li><code>nopen</code> containing the number of open nodes in the branch and bound tree</li></ul></li></ol></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ml-unito/PartitionedLS.jl/blob/b1ebd22e5675fc6fdc450ce2b7019b0cdf6d1ea5/src/PartitionedLSBnB.jl#L3-L29">source</a></section><section><div><pre><code class="language-julia hljs">fit(
    m::PartLS,
    verbosity,
    X,
    y
) -&gt; Tuple{PartLSFitResult, Nothing, Any}
</code></pre><p>Fits a PartitionedLS Regression model to the given data and resturns the learnt model (see the Result section). It conforms to the MLJ interface.</p><p><strong>Arguments</strong></p><ul><li><code>m</code>: A <a href="#PartitionedLS.PartLS"><code>PartLS</code></a> model to fit</li><li><code>verbosity</code>: the verbosity level</li><li><code>X</code>: any matrix or table with <code>Continuous</code> element scitype.       Check column scitypes of a table <code>X</code> with <code>schema(X)</code>.</li><li><code>y</code>: any vector with <code>Continuous</code> element scitype. Check scitype with <code>scitype(y)</code>. </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ml-unito/PartitionedLS.jl/blob/b1ebd22e5675fc6fdc450ce2b7019b0cdf6d1ea5/src/PartitionedLS.jl#L300-L313">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJModelInterface.predict" href="#MLJModelInterface.predict"><code>MLJModelInterface.predict</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">predict(
    α::AbstractVector{&lt;:AbstractFloat},
    β::AbstractVector{&lt;:AbstractFloat},
    t::AbstractFloat,
    P::Matrix{Int64},
    X::Matrix{&lt;:AbstractFloat}
) -&gt; Any
</code></pre><p><strong>Result</strong></p><p>the prediction for the partitioned least squares problem with solution α, β, t over the dataset X and partition matrix P</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ml-unito/PartitionedLS.jl/blob/b1ebd22e5675fc6fdc450ce2b7019b0cdf6d1ea5/src/PartitionedLS.jl#L125-L130">source</a></section><section><div><pre><code class="language-julia hljs">predict(
    model::PartLSFitResult,
    X::Matrix{&lt;:AbstractFloat}
) -&gt; Any
</code></pre><p>Make predictions for the datataset <code>X</code> using the PartialLS model <code>model</code>.</p><p><strong>Arguments</strong></p><ul><li><code>model</code>: a <a href="#PartitionedLS.PartLSFitResult">PartLSFitResult</a></li><li><code>X</code>: any matrix or table with <code>Continuous</code> element scitype containing the       examples for which the predictions are sought. Check column scitypes       of a table <code>X</code> with <code>schema(X)</code>.</li></ul><p><strong>Return</strong></p><p>the predictions of the given model on examples in X.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ml-unito/PartitionedLS.jl/blob/b1ebd22e5675fc6fdc450ce2b7019b0cdf6d1ea5/src/PartitionedLS.jl#L136-L150">source</a></section><section><div><pre><code class="language-julia hljs">predict(model::PartLS, fitresult, X) -&gt; Any
</code></pre><p>Make predictions for the datataset <code>X</code> using the PartitionedLS model <code>model</code>. It conforms to the MLJ interface.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ml-unito/PartitionedLS.jl/blob/b1ebd22e5675fc6fdc450ce2b7019b0cdf6d1ea5/src/PartitionedLS.jl#L335-L340">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PartitionedLS.homogeneousCoords" href="#PartitionedLS.homogeneousCoords"><code>PartitionedLS.homogeneousCoords</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Rewrites X and P in homogeneous coordinates. The result is a tuple (Xo, Po) where Xo is the homogeneous version of X and Po is the homogeneous version of P.</p><p><strong>Arguments</strong></p><ul><li><code>X</code>: any matrix or table with <code>Continuous</code> element scitype.       Check column scitypes of a table <code>X</code> with <code>schema(X)</code>. </li><li><code>P</code>: the partition matrix</li></ul><p><strong>Return</strong></p><ul><li><code>Xo</code>: the homogeneous version of X</li><li><code>Po</code>: the homogeneous version of P</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ml-unito/PartitionedLS.jl/blob/b1ebd22e5675fc6fdc450ce2b7019b0cdf6d1ea5/src/PartitionedLS.jl#L62-L74">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PartitionedLS.regularizeProblem" href="#PartitionedLS.regularizeProblem"><code>PartitionedLS.regularizeProblem</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Adds regularization terms to the problem. The regularization terms are added to the objective function as a sum of squares of the α variables. The regularization parameter η controls the strength of the regularization.</p><p><strong>Arguments</strong></p><ul><li><code>X</code>: any matrix or table with <code>Continuous</code> element scitype.       Check column scitypes of a table <code>X</code> with <code>schema(X)</code>.</li><li><code>y</code>: any vector with <code>Continuous</code> element scitype. Check scitype with <code>scitype(y)</code>. </li><li><code>P</code>: the partition matrix</li><li><code>η</code>: the regularization parameter</li></ul><p><strong>Return</strong></p><ul><li><code>Xn</code>: the new data matrix</li><li><code>yn</code>: the new target vector</li></ul><p><strong>Main idea</strong></p><p>K new rows are added to the data matrix X, row <span>$k \in \{1 \dots K\}$</span> is a vector of zeros except for the components that corresponds to features belonging to the k-th partition, which is set to sqrt(η). The target vector y is extended with K zeros.</p><p>The point of this change is that when the objective function is evaluated as <span>$math \|Xw - y\|^2$</span>, the new part of   the matrix contributes to the loss with a factor of  <span>$η \sum \|w_i\|^2$</span> . This is equivalent to adding a regularization   term to the objective function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ml-unito/PartitionedLS.jl/blob/b1ebd22e5675fc6fdc450ce2b7019b0cdf6d1ea5/src/PartitionedLS.jl#L82-L106">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="examples/example/">Example »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.3.0 on <span class="colophon-date" title="Wednesday 10 April 2024 02:16">Wednesday 10 April 2024</span>. Using Julia version 1.10.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
